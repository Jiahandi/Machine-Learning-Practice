tre$father[fa+i] <- fa
create_node(subset(Data,Data[[varname[i]]]==value_op[j],select= -temp ))
}
}
}
}
create_node(data)
create_node(data)
function (x, i, j, drop = if (missing(i)) TRUE else length(cols) ==
1)
{
{
{
{
{
{
{
{
{
{
value_op <- unique(unlist(Data[varname[i]]))
}}}}
}}}}}
}}}}}}}}}}
debugSource('F:/study/学校课程/ML/DecisionTree.R')
load("DecisionTree")
cal_entropy <- function(Data){
h <- 0
amount <- length(Data)
#size of possible value
value_op <- unique(Data)
value_ops <- length(value_op)
for(i in 1:value_ops){
temp <- length(Data[Data==value_op[i]])/amount
temp <- temp*log2(temp)
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
table(Data)
debugSource('F:/study/学校课程/ML/DecisionTree.R')
if(var_amount == 0){
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
View(Data)
kkk <- Data
View(data)
View(Data)
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
View(Data)
debugSource('F:/study/学校课程/ML/DecisionTree.R')
node_size
node_size
node_size
node_size
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
View(Data)
Data
length(Data)
nrow(Data)
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
View(Data)
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
Data[[varname[temp]]]==value_op[i]
Data[[varname[temp]]]==value_op[1]
kk <- subset(Data,Data[[varname[temp]]]==value_op[1],select= -temp )
nrow(kk)
class(kk)
kk == NULL
debugSource('F:/study/学校课程/ML/DecisionTree.R')
source('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
debugSource('F:/study/学校课程/ML/DecisionTree.R')
#a
library(ISLR)
gas.med = median(Auto$mpg)
new.var = ifelse(Auto$mpg > gas.med, 1, 0)
Auto$mpglevel = as.factor(new.var)
library(ISLR)
gas.med = median(Auto$mpg)
binary.var = ifelse(Auto$mpg > gas.med, 1, 0)
Auto$mpglevel = as.factor(binary.var)
binary.var
#b
library(e1071)
set.seed(3255)
tune.out = tune(svm, mpglevel~., data=Auto, kernel="linear", ranges=list(cost=c(0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
set.seed(21)
tune.out = tune(svm, mpglevel~., data=Auto, kernel="polynomial", ranges=list(cost=c(0.1, 1, 5, 10), degree=c(2, 3, 4)))
summary(tune.out)
#The lowest cross-validation error is obtained when cost=10&degree=2
set.seed(463)
tune.out = tune(svm, mpglevel~., data=Auto, kernel="radial", ranges=list(cost=c(0.1, 1, 5, 10), gamma=c(0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
#d
svm.linear = svm(mpglevel~., data=Auto, kernel="linear", cost=1)
svm.poly = svm(mpglevel~., data=Auto, kernel="polynomial", cost=10, degree=2)
svm.radial = svm(mpglevel~., data=Auto, kernel="radial", cost=10, gamma=0.01)
plotpairs = function(fit){
for (name in names(Auto)[!(names(Auto) %in% c("mpg", "mpglevel","name"))]) {
plot(fit, Auto, as.formula(paste("mpg~", name, sep="")))
}
}
plotpairs(svm.linear)
plotpairs(svm.poly)
plotpairs(svm.radial)
install("xlsx")
install.packages("xlsx")
a <- read.xlsx("0 (1).xls")
library(xlsx)
install.packages("rJava")
library(xlsx)
library(rJave)
library("rJava", lib.loc="~/R/win-library/3.2")
detach("package:rJava", unload=TRUE)
library("rJava", lib.loc="~/R/win-library/3.2")
detach("package:rJava", unload=TRUE)
library("rJava", lib.loc="~/R/win-library/3.2")
detach("package:rJava", unload=TRUE)
library("rJava", lib.loc="~/R/win-library/3.2")
?read
read.table()
read.table("0 (1).xls")
read.table("0 (1).xls",header = TRUE, fileEncoding = "utf-8")
install.packages("readxl")
library(readxl)
read_excel("0 (1).xls")
read_excel("0 (1).xls")
Pomo <- read.csv("pomotodo.csv", header = TRUE)
View(Pomo)
View(Pomo)
View(Pomo)
save(Pomo,file = "myPomo")
clear
clear()
ls()
remove(ls())
rm(ls())
rm(list < -ls())
rm(list <- ls())
rm(list = ls())
data<- read.table("data.csv",sep=";",header=TRUE,dec=".",row.names=1)
data
Xc=scale(data,center=TRUE,scale=FALSE)
Xc
Mcov=(1/10)*t(Xc)%*%Xc
Mcov
pc=eigen(Mcov)
pc$values
pc$vectors
Xc%*%pc$vectors
plot(data)
Xc=scale(data,center=TRUE,scale=FALSE)
Xc
data
data(9)
data$9
data[9]
data[:,9]
data[,9]
data[9,]
t(data[9,])
t(data[9,]).*(1,0)
t(data[9,])*(1,0)
t(data[9,])*[1,0]
[1,0]
{1,0}
(1,0)
(1 0)
a
[1,0]
(1 2)
c(1,2)
c(1,2;3,4)
matrix(1,2)
matrix(1,2;3,4)
c(1,0)
data[9,]
data[9,]*c(1,0)
t(data[9,])*c(1,0)
t(data[9,]).*c(1,0)
t(data[9,])%*%c(1,0)
c(1,0)*t(data[9,])
tcrossprod(data[9,],c(1,0))
tcrossprod(t(data[9,]),t(c(1,0)))
t(data[9,])%*%c(1,0)
data[9,]%*%c(1,0)
data[9,]
c(1,0)
as.vector(data[9,])
as.vector(data[9,])%*%as.vector(c(1,0))
data[9,]*c(1,0)
sum(data[9,]*c(1,0))
Mcov=(1/10)*t(Xc)%*%Xc
Mcov
pc=eigen(Mcov)
pc$values
pc$vectors
Xc%*%pc$vectors
pc
per=pc$values/sum(ps$values)*100
per=pc$values/sum(pc$values)*100
###
pr.out <- prcomp(data,scale=FALSE)
summary(pr.out)
pr.out$rotation
biplot(pr.out,scale=0)
Xc$rotation
Xc
pr.out$rotation
data*pr.out$rotation
pr.out
Xc*pr.out$rotation
Xc
data
Xc
Xc$
data
data-Xc
data
Xc
Xc
Xc*pr.out$rotation
dim(Xc)
dim(data)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x
x[1:25,2]=x[1:25,2]-4
x
km.out=kmeans(x,2,nstart=20)
km.out$cluster
plot(x, col=(km.out$cluster+1), main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)
set.seed(4)
km.out=kmeans(x,3,nstart=20)
km.out
plot(x, col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
set.seed(3)
km.out=kmeans(x,3,nstart=1)
km.out$tot.withinss
km.out=kmeans(x,3,nstart=20)
km.out$tot.withinss
read("wine.data")
read.csv("wine.data")
a <- data.frame(read.csv("wine.data"))
a
wine <- data.frame(read.csv("wine.data"))
colnames(wine) <- c("Alcohol","Malic acid","Ash","Alcalinity of ash","Magnesium","Total phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color intensity","Hue","OD280/OD315","Proline")
wine
wine$Hue
km.out=kmeans(wine,3,nstart = 20)
km.out$cluster
wine[1,2:]
wine[1,2;]
wine[1:3]
View(wine)
km.out=kmeans(wine[2:13],3,nstart = 20)
km.out$cluster
plot(wine[1], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
plot(wine[2:4], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
plot(wine[2:3], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
plot(wine[2:4], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
plot(wine[3:4], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
set.seed(2)
wine <- data.frame(read.csv("wine.data"))
colnames(wine) <- c("Alcohol","Malic acid","Ash","Alcalinity of ash","Magnesium","Total phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color intensity","Hue","OD280/OD315","Proline")
km.out=kmeans(wine[2:13],3,nstart = 20)
plot(wine[3:4], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
set.seed(2)
wine <- data.frame(read.csv("wine.data"))
colnames(wine) <- c("Alcohol","Malic acid","Ash","Alcalinity of ash","Magnesium","Total phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color intensity","Hue","OD280/OD315","Proline")
km.out=kmeans(wine[2:13],3,nstart = 20)
set.seed(2)
wine <- data.frame(read.csv("wine.data"))
colnames(wine) <- c("Alcohol","Malic acid","Ash","Alcalinity of ash","Magnesium","Total phenols","Flavanoids","Nonflavanoid phenols","Proanthocyanins","Color intensity","Hue","OD280/OD315","Proline")
km.out=kmeans(wine[1:13],3,nstart = 20)
plot(wine[3:4], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
plot(wine[1], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
km.out=kmeans(wine[1],3,nstart = 20)
km.out$cluster
plot(wine[1], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
plot(wine[1:2], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
km.out=kmeans(wine[2:13],3,nstart = 20)
km.out$cluster
plot(wine[1:2], col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
dist
?dist
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
hc.complete=hclust(dist(x), method="complete")
show(hc.complete)
dist(x)
hc
hc.complete
hc.average=hclust(dist(x), method="average")
hc.single=hclust(dist(x), method="single")
hc.complete
?hclust
hc.complete=hclust(dist(x), method="complete")
hc.average=hclust(dist(x), method="average")
hc.single=hclust(dist(x), method="single")
par(mfrow=c(1,3))
?par
?mfrow
??mforw
plot(hc.complete,main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)
cutree(hc.complete, 2)
cutree(hc.average, 2)
cutree(hc.single, 2)
cutree(hc.single, 4)
xsc=scale(x)
plot(hclust(dist(xsc), method="complete"), main="Hierarchical Clustering with Scaled Features")
x=matrix(rnorm(30*3), ncol=3)
dd=as.dist(1-cor(t(x)))
plot(hclust(dd, method="complete"), main="Complete Linkage with Correlation-Based Distance", xlab="", sub="")
summary(cars)
library(swirl)
ls(0)
ls()
clc
clc()
clear()
rm(list=ls())
swirl
swirl()
num_vect = c(0.5,55,-10,6)
c(0.5,55,-10,6)
info()
?c
num_vect
skip()
num_vect
tf <- num_vect <1
tf
num_vect >= 6
my_char <- c("My","name","is")
my_
my_char
paste(my_char,collapse = " ")
my_name <- c(my_char,"lunar")
my_name
paste(my_name,collapse=" ")
paste(my_name,sep=" ")
paste("Hello","world!",sep=" ")
paste(1:3,c("X","Y","Z"),sep="")
LETTERS
paste(LETTERS,1:4,sep="-")
bye()
swirl()
bye()
swirl()
plot(child~parent,galton)
View(galton)
?jitter
jitter(rep(0,7))
jitter(rep(2,7))
jitter(rep(2,7),3)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline,lwd = 3, col='red')
summary(regrline)
llm <- lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
fit$residuals
summary(fit)
mean(fit$residuals)
cov(fir$residuals,galton$parent)
cov(fit$residuals,galton$parent)
bye()
getwd()
setwd(F:\study\学校课程\ML\practice\Machine-Learning-Practice\Kaggle\Titanic)
setwd(F:/study/学校课程/ML/practice/Machine-Learning-Practice/Kaggle/Titanic)
setwd("F:/study/学校课程/ML/practice/Machine-Learning-Practice/Kaggle/Titanic")
read.csv("train")
read.csv("train.csv")
data <- read.csv("train.csv",header = TRUE)
View(data)
names(data)
data$Survived
names(data)
lifit <- lm(Survived~Sex+Age+Fare,data)
summary(lifit)
trainData <- read.csv("train.csv",header = TRUE)
names(trainData)
trainData$Survived
summary(lifit)
lifit <- lm(Survived~Sex+Age+Fare,trainData)
lifit
plot(trainDat$Survived,trainData$Sex)
plot(trainData$Survived,trainData$Sex)
a <- jitter(trainData$Survived,2)
plot(a,trainData$Sex)
a
?fix
summary(lifit)
lifit <- lm(Survived~Age+Fare,trainData)
summary(lifit)
coef(lifit)
names(trainData)
lifit <- lm(Survived~Sex+Age+Fare+Parch,trainData)
summary(lifit)
coef(lifit)
teD <- read.csv("test.csv",header = TRUE)
data.frame(teD$Sex,teD$Age)
data.frame(teD$Sex,teD$Age,teD$Fare,teD$Parch)
predict(lifit,data.frame(teD$Sex,teD$Age,teD$Fare,teD$Parch))
names(trainData)
View(teD)
predict(lifit,data.frame(teD$Age,teD$Fare,teD$Parch))
lifit <- lm(Survived~Sex+Age+Fare+Parch,trainData)
summary(lifit)
coef(lifit)
predict(lifit,data.frame(teD$Sex,teD$Age,teD$Fare,teD$Parch))
predict(lifit,data.frame(teD$Sexmale,teD$Age,teD$Fare,teD$Parch))
trainData$Sex[trainData$Sex == "male"] <- 1
trainData$Sex[trainData$Sex == "male"]
trainData$Sex[trainData$Sex == male]
trainData$Sex
trainData <- read.csv("train.csv",header = TRUE)
trainData$Sex
trainData$Sex[trainData$Sex == "male"] <- 1
trainData$Sex
trainData$Sex[trainData$Sex == "female"] <- 0
trainData$Sex
Sexd[trainData$Sex == "female"] <- 0
trainData <- read.csv("train.csv",header = TRUE)
teD <- read.csv("test.csv",header = TRUE)
names(trainData)
trainData$Sex
Sexd[trainData$Sex == "female"] <- 0
Sexd <- rep(nrow(trainData),0)
Sexd[trainData$Sex == "female"] <- 0
Sexd
trainData$Sexd <- rep(nrow(trainData),0)
Sexd[trainData$Sex == "male"] <- 1
Sexd
typeof(trainData)
predict(lifit,data.frame(teD$Age,teD$Fare,teD$Parch))
lifit <- lm(Survived~Age+Fare+Parch,trainData)
predict(lifit,data.frame(teD$Age,teD$Fare,teD$Parch))
teD
lifit <- lm(Survived~Sex+Age+Fare+Parch,trainData)
predict(lifit,data.frame(Sex=teD$Sex,Age=teD$Age,Fare=teD$Fare,Parch=teD$Parch))
ans <- predict(lifit,data.frame(Sex=teD$Sex,Age=teD$Age,Fare=teD$Fare,Parch=teD$Parch))
ans
View(teD)
View(trainData)
mean(trainData$Survived)
output[ans >0.5] <- 1
output <- rep(nrow(teD),0)
output[ans >0.5] <- 1
subFile <- data.frame(PassengerId=teD$PassengerId,Survived = output)
subFile
output
output <- rep(nrow(teD),0)
output[ans >0.5] <- 1
output
output <- rep(nrow(teD),0)
output
Sexd <- rep(nrow(trainData),0)
Sexd
output[output != 1] <- 0
output
output
Sexd <- rep(nrow(trainData),0)
Sexd[trainData$Sex == "female"] <- 0
Sexd[trainData$Sex == "male"] <- 1
Sexd
1!=1
output <- rep(nrow(teD),0)
output[ans >0.5] <- 1
sizeof(output)
typeof(output)
output
output[output.isna()] <- 0
ans
output[ans <0.5] <- 0
output
output[ans == NA] <- 0
output
ans
output[is.na(ans)] <- 0
output
subFile <- data.frame(PassengerId=teD$PassengerId,Survived = output)
subFile
save(subFile,file="submit.csv")
write.csv(subFile,file="submit.csv")
write.csv(subFile,file="submit.csv",row.names = F)
?write.csv
write.csv(subFile,file="submit.csv",row.names = F,quote = F)
