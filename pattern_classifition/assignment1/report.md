#模式识别　实验报告　　 
*SA17011050 陆承镪*   

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->
<!-- code_chunk_output -->

* [模式识别　实验报告](#模式识别-实验报告)
	* [实验数据集](#实验数据集)
	* [分类器](#分类器)
		* [Logistic Regression](#logistic-regression)
		* [SVM  (高斯核)](#svm-高斯核)
		* [GBDT](#gbdt)
	* [实验条件](#实验条件)
		* [Iris](#iris)
			* [LR](#lr)
			* [SVM](#svm)
			* [GBDT](#gbdt-1)
			* [结果比对](#结果比对)
		* [Adult](#adult)
			* [GBDT](#gbdt-2)
		* [Drive](#drive)
			* [LR](#lr-1)
			* [SVM](#svm-1)
			* [GBDT](#gbdt-3)
			* [实验对比](#实验对比)

<!-- /code_chunk_output -->


## 实验数据集　　
本次实验选取了三份数据集分别是：　　
+ [**Iris Data**](http://archive.ics.uci.edu/ml/datasets/Iris)   该数据集包含了三类鸢尾花的特征，每类有50条数据，特征为４维，分别是萼片和花瓣的宽度以及长度。[点此下载](http://archive.ics.uci.edu/ml/datasets/Iris)　　
+ [**Adult**](http://archive.ics.uci.edu/ml/datasets/Adult) 该数据集共有48842条数据，特征有14维，类别有两类——收入是否超过５万美元一年，分布大约是24%(超过５万美元)和76(不超过)。[点此下载](http://archive.ics.uci.edu/ml/datasets/Adult)　　
+ [**Sensorless Drive Diagnosis**](http://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis) 该数据集有58509条数据，共有11类，特征为49维。数据内容为汽车内各类传感器的数据，标签为汽车的故障状态。[点此下载](http://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis)     
  
实验的代码可以在[这里](https://github.com/geekinglcq/Machine-Learning-Practice/tree/master/pattern_classifition/assignment1)找到。  

## 分类器　　
本次实验，我选取了３个分类器。分别是：　　　
### Logistic Regression  
目标函数为：  
$$\underset{w, c}{min\,} \frac{1}{2}w^T w + C \sum_{i=1}^n \log(\exp(- y_i (X_i^T w + c)) + 1) .$$  
使用Python的sklearn工具包。  
**超参数**：  
+ `penalty`： 惩罚项  
+ `C`：正则化值  

### SVM  (高斯核)    
目标函数：   
$$min\;\; \frac{1}{2}||w||_2^2 +C\sum\limits_{i=1}^{m}\xi_i $$  
使用Python的sklearn工具包：
**超参数：**
+ `C`: 惩罚系数  
+ `gamma`:  核函数参数 $K(x, z) = exp(-\gamma||x-z||^2)\;\;\gamma>0$  

### GBDT  
总的目标函数为：  
$$\text{obj} = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i) $$  
这里$n$ 为集成的树的数量，对于第 $t$ 颗树，我们有：  
$$\text{obj}^{(t)} = \sum^T_{j=1} [G_jw_j + \frac{1}{2} (H_j+\lambda) w_j^2] +\gamma T$$  
**超参数：**  
+ `max_depth`: 树的最大深度  
+ `min_child_weight`: 最小子节点权重  
+ `gamma`: 最小节点分裂loss，数值越大模型越保守  
+ `subsample`： 采样比例  
+ `alpha`： l1正则化项  


## 实验条件  
### Iris  
在该数据集上，由于数据集较小，所以这里仅作为toy data用于上手。使用3折交叉验证，评估参数仅为精度判别精度Acc。   

#### LR     
下面是逻辑回归在该数据集上的实验数据，可以发现，惩罚函数l2相对来说较l1更优一些，而正则化值越大，判断的精度越高；但是可以看到，当C的数值取到5后，在另一参数取'l2'时就已经达到了测试集的最好成绩，再提高C的数值，只会造成过拟合。  

| param_C | param_penalty | mean_test_score | mean_train_score |
| ------- | ------------- | --------------- | ---------------- |
| 0.1     | l1            | 0.740000        | 0.729649         |
| 0.1     | l2            | 0.813333        | 0.819865         |
| 1       | l1            | 0.940000        | 0.966726         |
| 1       | l2            | 0.946667        | 0.963359         |
| 5       | l1            | 0.960000        | 0.969994         |
| 5       | l2            | 0.966667        | 0.969994         |
| 10      | l1            | 0.966667        | 0.973361         |
| 10      | l2            | 0.966667        | 0.976728         |
| 15      | l1            | 0.966667        | 0.973361         |
| 15      | l2            | 0.966667        | 0.980095         |
| 20      | l1            | 0.960000        | 0.973361         |
| 20      | l2            | 0.966667        | 0.983363         |
#### SVM   
这里我们也使用了3-fold验证，可以看出，svm的在测试集上的表现更好一些。  
超参数设置方面，可以看出gamma对结果影响不大，而C在适中的取值时效果有较明显的提升。  
基本上没有过拟合。  
|     | param_gamma | param_C | mean_train_accuracy | mean_test_accuracy |
| --- | ----------- | ------- | ------------------- | ------------------ |
| 0   | 1           | 0.1     | 0.963656            | 0.966667           |
| 1   | 0.5         | 0.1     | 0.953555            | 0.960000           |
| 2   | 0.1         | 0.1     | 0.930382            | 0.926667           |
| 3   | 0.5         | 0.1     | 0.953555            | 0.960000           |
| 4   | 0.01        | 0.1     | 0.920281            | 0.913333           |
| 5   | 1           | 1       | 0.983363            | 0.973333           |
| 6   | 0.5         | 1       | 0.969994            | 0.980000           |
| 7   | 0.1         | 1       | 0.973460            | 0.973333           |
| 8   | 0.5         | 1       | 0.969994            | 0.980000           |
| 9   | 0.01        | 1       | 0.936918            | 0.946667           |
| 10  | 1           | 5       | 0.979996            | 0.973333           |
| 11  | 0.5         | 5       | 0.979996            | 0.973333           |
| 12  | 0.1         | 5       | 0.980095            | 0.980000           |
| 13  | 0.5         | 5       | 0.979996            | 0.973333           |
| 14  | 0.01        | 5       | 0.966825            | 0.960000           |
| 15  | 1           | 10      | 0.986631            | 0.973333           |
| 16  | 0.5         | 10      | 0.973460            | 0.973333           |
| 17  | 0.1         | 10      | 0.980095            | 0.973333           |
| 18  | 0.5         | 10      | 0.973460            | 0.973333           |
| 19  | 0.01        | 10      | 0.973460            | 0.973333           |  

#### GBDT  
这里由于xgboost的超参数过多，也就不将所有实验结果贴出来了。  
总的来说，在该数据集上xgboost的超参数对结果影响并不大，也就两到三个百分点左右。在测试集上，xgboost能够取得的最好成绩是0.97333。  

#### 结果比对  
下面选择几类分类器在测试集上的最好成绩做比对。  
|LR|SVM|GBDT|
|--|--|--|
|0.966667|0.986631|0.973333|

### Adult  
由于该数据集含有大量难以序化的离散变量，所以该数据集仅使用xgboost来进行实验。  
#### GBDT  
这里我们使用对结果进行观察，可以看到：  
`gamma`对结果几乎没有影响，`subsample`有细微的影响，当数值略小于1时能取得较好的成绩。  
`min_child_weight`和`max_depth`的适度增长对结果都有提升，这是因为该数据集的特征较多，会需要较大的树深度。  
最后最好的结果是：  
`accuracy`:  0.86448  
`recall`: 0.65107
`precision`: 0.79166

### Drive  
该数据集使用交叉验证。这里我们因为涉及到多酚类问题，因此我们的指标除了精度（accuracy）外还引用了f1-score，由于是多分类，因此不能之间使用recall和precision计算得到的f1-score,这里我们使用了`f1_micro` 和`f1_macro`这两个指标。  
在多分类情况下，`f1_micro`在数值上就等于`accuracy`，而`f1_macro`则不考虑类别的不均衡问题，对每个类别求`f1`后平均。  
#### LR   
由下表可以看出，LR模型在该问题上变现不佳，最好的超参数设置下，也才取得了0.60左右的f1_micro。  
|     | param_C | param_penalty | mean_test_f1_micro |
| --- | ------- | ------------- | ------------------ |
| 0   | 0.1     | l1            | 0.565964           |
| 1   | 0.1     | l2            | 0.474474           |
| 2   | 1       | l1            | 0.603685           |
| 3   | 1       | l2            | 0.463416           |
| 4   | 5       | l1            | 0.589995           |
| 5   | 5       | l2            | 0.477909           |
| 6   | 10      | l1            | 0.583688           |
| 7   | 10      | l2            | 0.487737           |

|     | mean_test_f1_macro | mean_train_f1_micro | mean_train_f1_macro |
| --- | ------------------ | ------------------- | ------------------- |
| 0   | 0.545476           | 0.706473            | 0.698366            |
| 1   | 0.427811           | 0.580859            | 0.555440            |
| 2   | 0.598667           | 0.757422            | 0.756259            |
| 3   | 0.422966           | 0.553582            | 0.513301            |
| 4   | 0.587444           | 0.762028            | 0.761251            |
| 5   | 0.444232           | 0.599045            | 0.564368            |
| 6   | 0.581235           | 0.762148            | 0.761517            |
| 7   | 0.453105           | 0.593994            | 0.560197            |

#### SVM  
可以看出，在这个问题上，SVM对参数的设置十分敏感，以测试集的`f1_micro`指标为例，通过调整参数，其指标的变换范围从0.15到0.99。  
但是可以看出，由于参数空间相较于样本空间较小，所以我们的svm产生了严重的过拟合，甚至测试集的分数仅为训练集的1/10。  
| param_C | param_gamma | train_f1_micro | test_f1_macro | train_f1_macro | test_f1_micro |
| ------- | ----------- | -------------- | ------------- | -------------- | ------------- |
| 0.1     | 1           | 0.458297       | 0.039663      | 0.411348       | 0.096754      |
| 0.1     | 0.5         | 0.199790       | 0.045341      | 0.178535       | 0.096874      |
| 0.1     | 0.1         | 0.172546       | 0.072871      | 0.163447       | 0.102976      |
| 0.1     | 0.5         | 0.199790       | 0.045341      | 0.178535       | 0.096874      |
| 0.1     | 0.01        | 0.152130       | 0.086973      | 0.144249       | 0.107300      |
| 1       | 1           | 0.956391       | 0.089116      | 0.956433       | 0.106377      |
| 1       | 0.5         | 0.859201       | 0.104809      | 0.859491       | 0.115897      |
| 1       | 0.1         | 0.563127       | 0.151667      | 0.565990       | 0.156147      |
| 1       | 0.5         | 0.859201       | 0.104809      | 0.859491       | 0.115897      |
| 1       | 0.01        | 0.321002       | 0.176971      | 0.323992       | 0.188860      |
| 5       | 1           | 0.999316       | 0.09664       | 0.999316       | 0.111316      |
| 5       | 0.5         | 0.985592       | 0.119633      | 0.985594       | 0.127946      |
| 5       | 0.1         | 0.830812       | 0.22117       | 0.831047       | 0.222769      |
| 5       | 0.5         | 0.985592       | 0.119633      | 0.985594       | 0.127946      |
| 5       | 0.01        | 0.532516       | 0.277039      | 0.533781       | 0.291135      |
| 10      | 1           | 0.999957       | 0.096865      | 0.999957       | 0.111504      |
| 10      | 0.5         | 0.997641       | 0.121175      | 0.997641       | 0.129570      |
| 10      | 0.1         | 0.910313       | 0.246573      | 0.910305       | 0.246389      |
| 10      | 0.5         | 0.997641       | 0.121175      | 0.997641       | 0.129570      |
| 10      | 0.01        | 0.644713       | 0.348144      | 0.645000       | 0.363072      |

#### GBDT  
这里，`gamma`， `reg_alpha`对GBDT的影响不大；    

`max_depth`, `min_child_weight`的影响也不大，可能是因为特征空间较小，无需树的结构很深；  

`subsample`的变化会造成结果的显著变化，当该值小于0.5时，效果会非常差，这也是因为该数据集中的数据较为均衡，不需要欠采样有关。  
GBDT在该数据集上的最好表现为0.74877。  

#### 实验对比  
下面选择几类分类器在测试集上的最好成绩做比对。  
|LR|SVM|GBDT|
|--|--|--|
|0.603685|0.36307|0.74877|  
这里可以看出，GBDT几乎是完胜其他两个分类器。  
